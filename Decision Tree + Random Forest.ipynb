{
 "cells":[
  {
   "cell_type":"code",
   "source":[
    
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"E1ix2ceuvZHDiGxUSBd8Ev",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# COUNTRY+PROVINCE+VARIETY+WINERY+PRICE\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('decisiontree_dataframe.csv', delimiter=',')\n",
    "\n",
    "\n",
    "df['points_nominal'] = pd.cut(df['points'], [80, 84, 88, 92, 96, 100], \n",
    "                              labels=['normal quality', 'good quality', 'high quality', \n",
    "                                      'very high quality', 'excellent quality'])\n",
    "df = df.drop(columns=['points'])\n",
    "\n",
    "df= df.dropna(subset=['country', 'province', 'variety', 'winery','price','points_nominal'])\n",
    "\n",
    "Q1 = df['price'].quantile(0.25)\n",
    "Q3 = df['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# identify the outliers using the IQR method\n",
    "outliers = df[(df['price'] < (Q1 - 1.5 * IQR)) | (df['price'] > (Q3 + 1.5 * IQR))]\n",
    "# drop the outlier rows from the DataFrame\n",
    "df = df.drop(outliers.index)\n",
    "\n",
    "df.info()\n",
    "# Define input and output features\n",
    "X = df[['country', 'province', 'variety', 'winery','price']]\n",
    "y = df['points_nominal']\n",
    "\n",
    "# One-hot encode input features\n",
    "encoder = OneHotEncoder()\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Fit Gradient Boosting model\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "score = model.score(X_test, y_test)\n",
    "print('Accuracy:', score)"
   ],
   "execution_count":3,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 187705 entries, 1 to 217779\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count   Dtype   \n",
      "---  ------          --------------   -----   \n",
      " 0   country         187705 non-null  object  \n",
      " 1   price           187705 non-null  float64 \n",
      " 2   province        187705 non-null  object  \n",
      " 3   variety         187705 non-null  object  \n",
      " 4   winery          187705 non-null  object  \n",
      " 5   color           178986 non-null  object  \n",
      " 6   points_nominal  187705 non-null  category\n",
      "dtypes: category(1), float64(1), object(5)\n",
      "memory usage: 10.2+ MB\n",
      "Accuracy: 0.6599984017474229\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"2W42oslWNceOzWQgckYq7B",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# COUNTRY+PROVINCE+VARIETY+WINERY+PRICE\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "dftotal = pd.read_csv('combined_dataset.csv', delimiter=',')\n",
    "\n",
    "# Create the second DataFrame\n",
    "df = pd.read_csv('decisiontree_dataframe.csv', delimiter=',')\n",
    "\n",
    "# Take the 'A' column from df1 and add it to df2\n",
    "df['region1'] = dftotal['region_1']\n",
    "\n",
    "df['points_nominal'] = pd.cut(df['points'], [80, 84, 88, 92, 96, 100], \n",
    "                              labels=['normal quality', 'good quality', 'high quality', \n",
    "                                      'very high quality', 'excellent quality'])\n",
    "df = df.drop(columns=['points'])\n",
    "\n",
    "df= df.dropna(subset=['country', 'province', 'variety', 'winery','price','region1','points_nominal'])\n",
    "\n",
    "Q1 = df['price'].quantile(0.25)\n",
    "Q3 = df['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# identify the outliers using the IQR method\n",
    "outliers = df[(df['price'] < (Q1 - 1.5 * IQR)) | (df['price'] > (Q3 + 1.5 * IQR))]\n",
    "# drop the outlier rows from the DataFrame\n",
    "df = df.drop(outliers.index)\n",
    "\n",
    "df.info()\n",
    "# Define input and output features\n",
    "X = df[['country', 'province', 'variety', 'winery','price', 'region1']]\n",
    "y = df['points_nominal']\n",
    "\n",
    "# One-hot encode input features\n",
    "encoder = OneHotEncoder()\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Fit Gradient Boosting model\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "score = model.score(X_test, y_test)\n",
    "print('Accuracy:', score)"
   ],
   "execution_count":7,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 158266 entries, 2 to 217749\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count   Dtype   \n",
      "---  ------          --------------   -----   \n",
      " 0   country         158266 non-null  object  \n",
      " 1   price           158266 non-null  float64 \n",
      " 2   province        158266 non-null  object  \n",
      " 3   variety         158266 non-null  object  \n",
      " 4   winery          158266 non-null  object  \n",
      " 5   color           150994 non-null  object  \n",
      " 6   region1         158266 non-null  object  \n",
      " 7   points_nominal  158266 non-null  category\n",
      "dtypes: category(1), float64(1), object(6)\n",
      "memory usage: 9.8+ MB\n",
      "Accuracy: 0.6001769128704113\n"
     ],
     "output_type":"stream"
    },
    {
     "name":"stderr",
     "text":[
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/IPython\/core\/interactiveshell.py:3457: DtypeWarning: Columns (9,10,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"c2rZ8vr2dAHvRTqN2Dtn2N",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('decisiontree_dataframe.csv', delimiter=',')\n",
    "\n",
    "# Define target variable and input features\n",
    "df['points_nominal'] = pd.cut(df['points'], [80, 84, 88, 92, 96, 100], \n",
    "                              labels=['normal quality', 'good quality', 'high quality', \n",
    "                                      'very high quality', 'excellent quality'])\n",
    "df = df.drop(columns=['points'])\n",
    "df = df.dropna(subset=['country', 'province', 'variety', 'winery','price','points_nominal'])\n",
    "Q1 = df['price'].quantile(0.25)\n",
    "Q3 = df['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = df[(df['price'] < (Q1 - 1.5 * IQR)) | (df['price'] > (Q3 + 1.5 * IQR))]\n",
    "df = df.drop(outliers.index)\n",
    "X = df[['country', 'province', 'variety', 'winery', 'price']]\n",
    "y = df['points_nominal']\n",
    "\n",
    "# One-hot encode input features\n",
    "encoder = OneHotEncoder()\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define random forest classifier and parameter distributions for randomized search\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "param_dist = {\n",
    "    'n_estimators': randint(10, 500),\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 20),\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Perform randomized search for hyperparameter tuning\n",
    "rf_random = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=50, cv=3, random_state=42)\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "# Print best hyperparameters and accuracy score\n",
    "print('Best hyperparameters:', rf_random.best_params_)\n",
    "print('Accuracy:', rf_random.best_score_)"
   ],
   "execution_count":1,
   "outputs":[
    {
     "ename":"ParserError",
     "evalue":"ParserError: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "traceback":[
      "\u001b[0;31m---------------------------------------------------------------------------",
      "Traceback (most recent call last)",
      "    at line 9 in <module>",
      "    at line 311 in wrapper(*args, **kwargs)",
      "    at line 586 in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)",
      "    at line 482 in _read(filepath_or_buffer, kwds)",
      "    at line 811 in __init__(self, f, engine, **kwds)",
      "    at line 1040 in _make_engine(self, engine)",
      "    at line 69 in __init__(self, src, **kwds)",
      "    at line 0 in pandas._libs.parsers.TextReader.__cinit__()",
      "    at line 0 in pandas._libs.parsers.TextReader._get_header()",
      "    at line 0 in pandas._libs.parsers.TextReader._tokenize_rows()",
      "    at line 0 in pandas._libs.parsers.raise_parser_error()",
      "ParserError: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ],
     "output_type":"error"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"bRV2barNg2kM7Fs9d4hZFU",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# COUNTRY+COLOR+VARIETY+WINERY+PRICE\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('decisiontree_dataframe.csv', delimiter=',')\n",
    "\n",
    "df['points_nominal'] = pd.cut(df['points'], [80, 84, 88, 92, 96, 100], \n",
    "                              labels=['normal quality', 'good quality', 'high quality', \n",
    "                                      'very high quality', 'excellent quality'])\n",
    "df = df.drop(columns=['points'])\n",
    "\n",
    "df= df.dropna(subset=['country', 'color', 'variety', 'winery','price','points_nominal'])\n",
    "\n",
    "Q1 = df['price'].quantile(0.25)\n",
    "Q3 = df['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# identify the outliers using the IQR method\n",
    "outliers = df[(df['price'] < (Q1 - 1.5 * IQR)) | (df['price'] > (Q3 + 1.5 * IQR))]\n",
    "# drop the outlier rows from the DataFrame\n",
    "df = df.drop(outliers.index)\n",
    "\n",
    "df.info()\n",
    "# Define input and output features\n",
    "X = df[['country', 'variety', 'winery','price','color']]\n",
    "y = df['points_nominal']\n",
    "\n",
    "# One-hot encode input features\n",
    "encoder = OneHotEncoder()\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit decision tree model\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "score = model.score(X_test, y_test)\n",
    "print('Accuracy:', score)"
   ],
   "execution_count":14,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 179174 entries, 1 to 217779\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count   Dtype   \n",
      "---  ------          --------------   -----   \n",
      " 0   country         179174 non-null  object  \n",
      " 1   price           179174 non-null  float64 \n",
      " 2   province        179174 non-null  object  \n",
      " 3   variety         179174 non-null  object  \n",
      " 4   winery          179174 non-null  object  \n",
      " 5   color           179174 non-null  object  \n",
      " 6   points_nominal  179174 non-null  category\n",
      "dtypes: category(1), float64(1), object(5)\n",
      "memory usage: 9.7+ MB\n",
      "Accuracy: 0.6580717175945305\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"zxKsMkf3RedQkeHo4l7h0y",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# COUNTRY+PROVINCE+VARIETY+WINERY+PRICE\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('decisiontree_dataframe.csv', delimiter=',')\n",
    "\n",
    "df['points_nominal'] = pd.cut(df['points'], [80, 84, 88, 92, 96, 100], \n",
    "                              labels=['normal quality', 'good quality', 'high quality', \n",
    "                                      'very high quality', 'excellent quality'])\n",
    "df = df.drop(columns=['points'])\n",
    "\n",
    "df= df.dropna(subset=['country', 'province', 'variety', 'winery','price','points_nominal'])\n",
    "\n",
    "Q1 = df['price'].quantile(0.25)\n",
    "Q3 = df['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# identify the outliers using the IQR method\n",
    "outliers = df[(df['price'] < (Q1 - 1.5 * IQR)) | (df['price'] > (Q3 + 1.5 * IQR))]\n",
    "# drop the outlier rows from the DataFrame\n",
    "df = df.drop(outliers.index)\n",
    "\n",
    "df.info()\n",
    "# Define input and output features\n",
    "X = df[['country', 'province', 'variety', 'winery','price']]\n",
    "y = df['points_nominal']\n",
    "\n",
    "# One-hot encode input features\n",
    "encoder = OneHotEncoder()\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit decision tree model\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "score = model.score(X_test, y_test)\n",
    "print('Accuracy:', score)"
   ],
   "execution_count":15,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 179174 entries, 1 to 217779\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count   Dtype   \n",
      "---  ------          --------------   -----   \n",
      " 0   country         179174 non-null  object  \n",
      " 1   price           179174 non-null  float64 \n",
      " 2   province        179174 non-null  object  \n",
      " 3   variety         179174 non-null  object  \n",
      " 4   winery          179174 non-null  object  \n",
      " 5   color           179174 non-null  object  \n",
      " 6   points_nominal  179174 non-null  category\n",
      "dtypes: category(1), float64(1), object(5)\n",
      "memory usage: 9.7+ MB\n",
      "Accuracy: 0.5810799497697782\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"qynWuD3pdw3JqaV4Z4zYLT",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "is_country = ['is Germany', 'is Austria', 'is Australia', 'is Argentina', 'is Chile', 'is Portugal', 'is Spain', 'is Italy', 'is France', 'is US', 'is Australian']\n",
    "is_year = ['is 1997', 'is 1998', 'is 1999', 'is 2000', 'is 2001', 'is 2002', 'is 2003', 'is 2004', 'is 2005', 'is 2006', 'is 2007', 'is 2008', 'is 2009', 'is 2010', 'is 2011', 'is 2012', 'is 2013', 'is 2014', 'is 2015', 'is 2016', 'is 2017']\n",
    "is_region = ['is European', 'is North American', 'is South American', 'is Australian']\n",
    "is_variety = ['is Rosé', 'is Merlot', 'is Syrah', 'is Riesling', 'is Sauvignon Blanc', 'is Bordeaux-style Red Blend', 'is Red Blend', 'is Cabernet Sauvignon', 'is Chardonnay', 'is Pinot Noir']\n",
    "is_color = ['is Rosé', 'is Bordeaux-style Red Blend', 'is Red Blend', 'is Red', 'is White', 'is Sparkling']"
   ],
   "execution_count":10,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"AlzLMicxae3QJFf47wmyb4",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the merged_dataframes_total dataframe\n",
    "merged_dataframes_total = pd.read_csv('binarydataframe.csv')\n",
    "\n",
    "# calculate the interquartile range for the 'price' column\n",
    "Q1 = merged_dataframes_total['price'].quantile(0.25)\n",
    "Q3 = merged_dataframes_total['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# identify the outliers using the IQR method\n",
    "outliers = merged_dataframes_total[(merged_dataframes_total['price'] < (Q1 - 1.5 * IQR)) | (merged_dataframes_total['price'] > (Q3 + 1.5 * IQR))]\n",
    "\n",
    "# drop the outlier rows from the DataFrame\n",
    "merged_dataframes_total = merged_dataframes_total.drop(outliers.index)\n",
    "\n",
    "merged_dataframes_total = merged_dataframes_total.dropna(subset=['price'])\n",
    "\n",
    "null_columns = merged_dataframes_total.columns[merged_dataframes_total.isnull().any()]\n",
    "print('Null Columns \\n', merged_dataframes_total[null_columns].isnull().sum().head(50))\n",
    " \n",
    "\n",
    "merged_dataframes_total['points'] = merged_dataframes_total['points'].astype(str)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = merged_dataframes_total[is_country+is_variety+['price']] # drop the target variable 'points'\n",
    "y = merged_dataframes_total['points']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a decision tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model's accuracy and confusion matrix\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(clf, filled=True, feature_names=X.columns, class_names=y.unique())\n",
    "plt.show()"
   ],
   "execution_count":20,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Null Columns \n",
      " is 1997    87639\n",
      "is 1998    87639\n",
      "is 1999    87639\n",
      "is 2000    87639\n",
      "is 2001    87639\n",
      "is 2002    87639\n",
      "is 2003    87639\n",
      "is 2004    87639\n",
      "is 2005    87639\n",
      "is 2006    87639\n",
      "is 2007    87639\n",
      "is 2008    87639\n",
      "is 2009    87639\n",
      "is 2010    87639\n",
      "is 2011    87639\n",
      "is 2012    87639\n",
      "is 2013    87639\n",
      "is 2014    87639\n",
      "is 2015    87639\n",
      "is 2016    87639\n",
      "is 2017    87639\n",
      "dtype: int64\n",
      "Accuracy: 0.1872544856141841\n",
      "Confusion Matrix:\n",
      " [[   1    1    7    7   34   36   33   36   27    4    7    3    0    1\n",
      "     0    0    0    0    0    0]\n",
      " [   0    5   12    6   57   36   58   80   48    6   15    4    3    1\n",
      "     1    0    0    0    0    0]\n",
      " [   0    3   16   18   71  103  124  226  143   19   60   21   15    1\n",
      "     0    0    0    0    0    0]\n",
      " [   0    5   14   59  195  183  164  335  201   25   74   26   19    0\n",
      "     0    0    0    0    0    0]\n",
      " [   1    4   18   43  260  342  382  678  382   54  195   52   59    6\n",
      "     2    0    0    0    0    0]\n",
      " [   0    0   10   33  244  478  484  899  558   67  277   72   83    8\n",
      "     2    0    0    0    0    0]\n",
      " [   0    3    9   26  217  404  584 1187  692  110  394  124   95   22\n",
      "     1    0    0    0    0    0]\n",
      " [   1    6   11   23  171  327  484 1848 1066  176  663  174  153   39\n",
      "     4    2    0    0    0    0]\n",
      " [   0    2   12   10  120  201  334 1332 1287  222  769  273  222   44\n",
      "     6    0    0    0    0    0]\n",
      " [   1    2    3    4   56   95  173  765  804  283  763  237  204   38\n",
      "    12    1    0    0    0    0]\n",
      " [   0    1    2    1   36   61  138  791  917  278 1162  368  344  103\n",
      "    10    2    0    0    0    0]\n",
      " [   0    1    1    1   12   34   68  407  547  165  894  429  334   98\n",
      "    17    2    1    0    0    0]\n",
      " [   0    1    0    0    3   11   55  208  361  128  646  388  458  136\n",
      "    18    2    0    0    0    0]\n",
      " [   0    1    0    0    3    5   10   91  126   48  407  234  290  143\n",
      "    23    3    1    0    0    0]\n",
      " [   0    0    0    0    3    3    3   25   49   21  164  109  194   76\n",
      "    36    3    0    0    0    0]\n",
      " [   0    0    0    0    1    1    1    8    8    5   54   36   70   38\n",
      "    13    6    0    0    0    0]\n",
      " [   0    0    1    0    0    0    0    2    4    1   18    7   27    6\n",
      "     5    2    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    1    1    5    4\n",
      "     1    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    4    1\n",
      "     0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    1    0\n",
      "     0    0    0    0    0    0]]\n",
      "Error in callback <function flush_figures at 0x7f7cceb4a5e0> (for post_execute):\n"
     ],
     "output_type":"stream"
    },
    {
     "ename":"KeyboardInterrupt",
     "evalue":"KeyboardInterrupt: ",
     "traceback":[
      "\u001b[0;31m---------------------------------------------------------------------------",
      "Traceback (most recent call last)",
      "    at line 120 in flush_figures()",
      "    at line 40 in show(close, block)",
      "    at line 320 in display(include, exclude, metadata, transient, display_id, *objs, **kwargs)",
      "    at line 180 in format(self, obj, include, exclude)",
      "    at line 232 in fun(*args, **kw)",
      "    at line 224 in catch_format_error(method, self, *args, **kwargs)",
      "    at line 341 in __call__(self, obj)",
      "    at line 151 in print_figure(fig, fmt, bbox_inches, base64, **kwargs)",
      "    at line 2295 in print_figure(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)",
      "    at line 73 in draw_wrapper(artist, renderer, *args, **kwargs)",
      "    at line 50 in draw_wrapper(artist, renderer)",
      "    at line 2810 in draw(self, renderer)",
      "    at line 132 in _draw_list_compositing_images(renderer, parent, artists, suppress_composite)",
      "    at line 50 in draw_wrapper(artist, renderer)",
      "    at line 3082 in draw(self, renderer)",
      "    at line 132 in _draw_list_compositing_images(renderer, parent, artists, suppress_composite)",
      "    at line 50 in draw_wrapper(artist, renderer)",
      "    at line 1981 in draw(self, renderer)",
      "    at line 50 in draw_wrapper(artist, renderer)",
      "    at line 702 in draw(self, renderer)",
      "    at line 50 in draw_wrapper(artist, renderer)",
      "    at line 609 in draw(self, renderer)",
      "    at line 278 in get_transform(self)",
      "    at line 296 in get_patch_transform(self)",
      "    at line 1784 in __init__(self, *args, **kwargs)",
      "    at line 121 in __init__(self, shorthand_name)",
      "KeyboardInterrupt: "
     ],
     "output_type":"error"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"UjHBs668rphy50MKiAmfEV",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('decisiontree_dataframe.csv', delimiter=';')\n",
    "\n",
    "df['points_nominal'] = pd.cut(df['points'], [80, 84, 88, 92, 96, 100], \n",
    "                              labels=['normal quality', 'good quality', 'high quality', \n",
    "                                      'very high quality', 'excellent quality'])\n",
    "\n",
    "df = df.drop(columns=['points'])\n",
    "df = df.dropna()\n",
    "df.info()\n",
    "\n",
    "# Define input and output features\n",
    "X = df[['country', 'province', 'variety', 'winery', 'color']]\n",
    "y = df['points_nominal']\n",
    "\n",
    "# Ordinal encode input features\n",
    "encoder = OrdinalEncoder()\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define parameter grid for random forest model\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Fit random forest model with hyperparameter tuning\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best hyperparameters and accuracy on test set\n",
    "print('Best hyperparameters:', grid_search.best_params_)\n",
    "score = grid_search.score(X_test, y_test)\n",
    "print('Accuracy:', score)"
   ],
   "execution_count":2,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 207029 entries, 0 to 207931\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count   Dtype   \n",
      "---  ------          --------------   -----   \n",
      " 0   country         207029 non-null  object  \n",
      " 1   province        207029 non-null  object  \n",
      " 2   variety         207029 non-null  object  \n",
      " 3   winery          207029 non-null  object  \n",
      " 4   color           207029 non-null  object  \n",
      " 5   points_nominal  207029 non-null  category\n",
      "dtypes: category(1), object(5)\n",
      "memory usage: 9.7+ MB\n"
     ],
     "output_type":"stream"
    },
    {
     "ename":"TerminatedWorkerError",
     "evalue":"TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGKILL(-9)}",
     "traceback":[
      "\u001b[0;31m---------------------------------------------------------------------------",
      "Traceback (most recent call last)",
      "    at line 39 in <module>",
      "    at line 891 in fit(self, X, y, groups, **fit_params)",
      "    at line 1392 in _run_search(self, evaluate_candidates)",
      "    at line 838 in evaluate_candidates(candidate_params, cv, more_results)",
      "    at line 1098 in __call__(self, iterable)",
      "    at line 975 in retrieve(self)",
      "    at line 567 in wrap_future_result(future, timeout)",
      "    at line 444 in result(self, timeout)",
      "    at line 389 in __get_result(self)",
      "TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGKILL(-9)}"
     ],
     "output_type":"error"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"NQk0GWKegfX27oBRT4doR7",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('decisiontree_dataframe.csv', delimiter=',')\n",
    "\n",
    "df['points_nominal'] = pd.cut(df['points'], [80, 84, 88, 92, 96, 100], \n",
    "                              labels=['normal quality', 'good quality', 'high quality', \n",
    "                                      'very high quality', 'excellent quality'])\n",
    "\n",
    "df = df.drop(columns=['points'])\n",
    "df= df.dropna()\n",
    "df.info()\n",
    "\n",
    "# Define input and output features\n",
    "X = df[['country', 'province', 'variety', 'winery', 'price']]\n",
    "y = df['points_nominal']\n",
    "\n",
    "# One-hot encode input features\n",
    "encoder = OneHotEncoder()\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit random forest model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "score = model.score(X_test, y_test)\n",
    "print('Accuracy:', score)"
   ],
   "execution_count":17,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 190701 entries, 1 to 217779\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count   Dtype   \n",
      "---  ------          --------------   -----   \n",
      " 0   country         190701 non-null  object  \n",
      " 1   price           190701 non-null  float64 \n",
      " 2   province        190701 non-null  object  \n",
      " 3   variety         190701 non-null  object  \n",
      " 4   winery          190701 non-null  object  \n",
      " 5   color           190701 non-null  object  \n",
      " 6   points_nominal  190701 non-null  category\n",
      "dtypes: category(1), float64(1), object(5)\n",
      "memory usage: 10.4+ MB\n"
     ],
     "output_type":"stream"
    },
    {
     "ename":"KeyboardInterrupt",
     "evalue":"KeyboardInterrupt: ",
     "traceback":[
      "\u001b[0;31m---------------------------------------------------------------------------",
      "Traceback (most recent call last)",
      "    at line 30 in <module>",
      "    at line 442 in fit(self, X, y, sample_weight)",
      "    at line 1085 in __call__(self, iterable)",
      "    at line 901 in dispatch_one_batch(self, iterator)",
      "    at line 819 in _dispatch(self, batch)",
      "    at line 208 in apply_async(self, func, callback)",
      "    at line 597 in __init__(self, batch)",
      "    at line 288 in __call__(self)",
      "    at line 288 in <listcomp>(.0)",
      "    at line 211 in __call__(self, *args, **kwargs)",
      "    at line 185 in _parallel_build_trees(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)",
      "    at line 937 in fit(self, X, y, sample_weight, check_input, X_idx_sorted)",
      "    at line 420 in fit(self, X, y, sample_weight, check_input, X_idx_sorted)",
      "KeyboardInterrupt: "
     ],
     "output_type":"error"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"9oEJdprYJhcm5L885T3zz6",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"CdZ8d6xVZOgfh8hJ6BUp8B",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  }
 ],
 "metadata":{
  "kernelspec":{
   "display_name":"Python",
   "language":"python",
   "name":"python"
  },
  "datalore":{
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[
    
   ],
   "report_row_ids":[
    
   ],
   "version":3
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}