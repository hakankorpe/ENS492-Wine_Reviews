{
 "cells":[
  {
   "cell_type":"code",
   "source":[
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('decisiontree_dataframe.csv', delimiter=';')\n",
    "\n",
    "df['points_nominal'] = pd.cut(df['points'], [80, 84, 88, 92, 96, 100], \n",
    "                              labels=['normal quality', 'good quality', 'high quality', \n",
    "                                      'very high quality', 'excellent quality'])\n",
    "\n",
    "df = df.drop(columns=['points'])\n",
    "df= df.dropna()\n",
    "df.info()\n",
    "\n",
    "# Define input and output features\n",
    "X = df[['country', 'province', 'variety', 'winery', 'color']]\n",
    "y = df['points_nominal']\n",
    "\n",
    "# One-hot encode input features\n",
    "encoder = OneHotEncoder()\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit XGBoost model\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "score = model.score(X_test, y_test)\n",
    "print('Accuracy:', score)"
   ],
   "execution_count":1,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 207029 entries, 0 to 207931\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count   Dtype   \n",
      "---  ------          --------------   -----   \n",
      " 0   country         207029 non-null  object  \n",
      " 1   province        207029 non-null  object  \n",
      " 2   variety         207029 non-null  object  \n",
      " 3   winery          207029 non-null  object  \n",
      " 4   color           207029 non-null  object  \n",
      " 5   points_nominal  207029 non-null  category\n",
      "dtypes: category(1), object(5)\n",
      "memory usage: 9.7+ MB\n",
      "[15:17:44] WARNING: ..\/src\/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 0.5026566198135536\n"
     ],
     "output_type":"stream"
    },
    {
     "name":"stderr",
     "text":[
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/xgboost\/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"6UXcDdUk6wB9cFzSNBcxTV",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  }
 ],
 "metadata":{
  "kernelspec":{
   "display_name":"Python",
   "language":"python",
   "name":"python"
  },
  "datalore":{
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[
    
   ],
   "report_row_ids":[
    
   ],
   "version":3
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}